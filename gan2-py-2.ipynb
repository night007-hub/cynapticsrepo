{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10475930,"sourceType":"datasetVersion","datasetId":6486761}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_seed = 42\ntorch.manual_seed(random_seed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 128\nNUM_WORKERS = int(os.cpu_count() / 2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlatent_dim = 100\nepochs = 50\nOUTPUT_DIR = \"./gan_generated_images\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\ndata_dir = '/kaggle/input/animeface007/gan.zip'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((64, 64)),       \n    transforms.ToTensor(),            \n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = ImageFolder(root=data_dir, transform=transform)\ndataset_size = len(dataset)\nprint(dataset_size )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(0.9 * dataset_size)\nval_size = dataset_size - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n        self.fc = nn.Linear(256 * 8 * 8, 1)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x), 0.2)\n        x = F.leaky_relu(self.conv2(x), 0.2)\n        x = F.leaky_relu(self.conv3(x), 0.2)\n        x = x.view(-1, 256 * 8 * 8)\n        x = self.fc(x)\n        return torch.sigmoid(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, latent_dim):\n        super().__init__()\n        self.fc = nn.Linear(latent_dim, 256 * 8 * 8)\n        self.ct1 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)\n        self.ct2 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\n        self.ct3 = nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.fc(x)\n        x = x.view(-1, 256, 8, 8)\n        x = F.relu(self.ct1(x))\n        x = F.relu(self.ct2(x))\n        x = torch.tanh(self.ct3(x))  # Output in range [-1, 1]\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.utils import save_image\ndef save_generated_images(generator, latent_dim, epoch, device):\n    generator.eval()  # Set generator to evaluation mode\n    with torch.no_grad():\n        latent_space = torch.randn(16, latent_dim).to(device)  # Generate 16 random samples\n        fake_images = generator(latent_space)\n        fake_images = (fake_images + 1) / 2  # Rescale to [0, 1] for saving as images\n        save_image(fake_images, os.path.join(OUTPUT_DIR, f\"epoch_{epoch+1}.png\"), nrow=4)\n    generator.train()  # Reset generator to training mode","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_gan(discriminator, generator, train_loader, latent_dim, epochs, device):\n    discriminator.to(device)\n    generator.to(device)\n    criterion = nn.BCELoss()\n\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    \n    # optimizer of learning rate\n    scheduler_d = optim.lr_scheduler.StepLR(d_optimizer, step_size=10, gamma=0.5)  # Decay every 10 epochs\n    scheduler_g = optim.lr_scheduler.StepLR(g_optimizer, step_size=10, gamma=0.5)  # Decay every 10 epochs\n\n    for epoch in range(epochs):\n        for real_images, _ in train_loader:\n            real_images = real_images.to(device)\n\n            d_optimizer.zero_grad()\n            real_labels = torch.ones(real_images.size(0), 1).to(device)\n            fake_labels = torch.zeros(real_images.size(0), 1).to(device)\n\n            real_outputs = discriminator(real_images)\n            d_real_loss = criterion(real_outputs, real_labels)\n\n            latent_space = torch.randn(real_images.size(0), latent_dim).to(device)\n            fake_images = generator(latent_space)\n            fake_outputs = discriminator(fake_images.detach())\n            d_fake_loss = criterion(fake_outputs, fake_labels)\n\n            d_loss = (d_real_loss + d_fake_loss) / 2  # Division by 2\n            d_loss.backward()\n            d_optimizer.step()\n\n            g_optimizer.zero_grad()\n            fake_outputs = discriminator(fake_images)\n            g_loss = criterion(fake_outputs, real_labels)\n            g_loss.backward()\n            g_optimizer.step()\n            \n        scheduler_d.step()\n        scheduler_g.step()\n        if (epoch + 1) % 5 == 0: \n            save_generated_images(generator, latent_dim, epoch, device)\n            print(f\"Epoch [{epoch+1}/{epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")\n            print(f\"Discriminator learning rate: {scheduler_d.get_last_lr()[0]:.6f}, Generator learning rate: {scheduler_g.get_last_lr()[0]:.6f}\")\n            print(f\"Images saved at epoch {epoch+1}.\")\n        else:\n            print(f\"Epoch [{epoch+1}/{epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")\n\ndiscriminator = Discriminator()\ngenerator = Generator(latent_dim)\n\ntrain_gan(discriminator, generator, train_loader, latent_dim, epochs=epochs, device=device)\n    \n     \n    \n     \n     \n     \n          ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}